{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The challenge:\n",
    "\n",
    "In this competition you’ll predict what types of trees there are in an area based on various geographic features.\n",
    "\n",
    "The competition datasets comes from a study conducted in four wilderness areas within the beautiful Roosevelt National Forest of northern Colorado. These areas represent forests with very little human disturbances – the existing forest cover types there are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "The data is in raw form and contains categorical data such as wilderness areas and soil type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:38.237234Z",
     "start_time": "2019-09-10T12:00:38.232275Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/learn-together'\n",
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:52.419081Z",
     "start_time": "2019-09-10T12:00:38.736011Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.csv\n",
      "data/test.csv\n",
      "data/sample_submission.csv\n",
      "data/sample_submission.csv.zip\n",
      "data/input\n",
      "data/test.csv.zip\n",
      "data/train.csv.zip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, \\\n",
    "    ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "for dirname, _, filenames in os.walk(DATA_DIR):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:52.423611Z",
     "start_time": "2019-09-10T12:00:52.420830Z"
    }
   },
   "outputs": [],
   "source": [
    "def report(y_true, y_pred):\n",
    "    print('Accuracy: %s' % accuracy_score(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.285025Z",
     "start_time": "2019-09-10T12:00:52.425333Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "test_df=pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.304772Z",
     "start_time": "2019-09-10T12:00:54.286388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1       2596      51      3                               258   \n",
       "1   2       2590      56      2                               212   \n",
       "2   3       2804     139      9                               268   \n",
       "3   4       2785     155     18                               242   \n",
       "4   5       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm     ...      Soil_Type32  \\\n",
       "0            221             232            148     ...                0   \n",
       "1            220             235            151     ...                0   \n",
       "2            234             238            135     ...                0   \n",
       "3            238             238            122     ...                0   \n",
       "4            220             234            150     ...                0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           5  \n",
       "1            0            0            0           5  \n",
       "2            0            0            0           2  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           5  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.373949Z",
     "start_time": "2019-09-10T12:00:54.305890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15121</td>\n",
       "      <td>2680</td>\n",
       "      <td>354</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2684</td>\n",
       "      <td>196</td>\n",
       "      <td>214</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15122</td>\n",
       "      <td>2683</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2654</td>\n",
       "      <td>201</td>\n",
       "      <td>216</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15123</td>\n",
       "      <td>2713</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2980</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15124</td>\n",
       "      <td>2709</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2950</td>\n",
       "      <td>208</td>\n",
       "      <td>201</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15125</td>\n",
       "      <td>2706</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2920</td>\n",
       "      <td>210</td>\n",
       "      <td>195</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0  15121       2680     354     14                                 0   \n",
       "1  15122       2683       0     13                                 0   \n",
       "2  15123       2713      16     15                                 0   \n",
       "3  15124       2709      24     17                                 0   \n",
       "4  15125       2706      29     19                                 0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                             2684   \n",
       "1                               0                             2654   \n",
       "2                               0                             2980   \n",
       "3                               0                             2950   \n",
       "4                               0                             2920   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm     ...       Soil_Type31  \\\n",
       "0            196             214            156     ...                 0   \n",
       "1            201             216            152     ...                 0   \n",
       "2            206             208            137     ...                 0   \n",
       "3            208             201            125     ...                 0   \n",
       "4            210             195            115     ...                 0   \n",
       "\n",
       "   Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0            0            0            0            0  \n",
       "1            0            0            0            0  \n",
       "2            0            0            0            0  \n",
       "3            0            0            0            0  \n",
       "4            0            0            0            0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.392597Z",
     "start_time": "2019-09-10T12:00:54.375716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape training csv: (15120, 56)\n",
      "shape test csv: (565892, 55)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape training csv: %s\" % str(train_df.shape)) \n",
    "print(\"shape test csv: %s\" % str(test_df.shape)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Ids\n",
    "**Let's delete the Id column in the training set but store it for the test set before deleting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.483118Z",
     "start_time": "2019-09-10T12:00:54.394792Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"Id\"], axis = 1)\n",
    "\n",
    "test_ids = test_df[\"Id\"]\n",
    "test_df = test_df.drop([\"Id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.511861Z",
     "start_time": "2019-09-10T12:00:54.485304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40', 'Cover_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.545340Z",
     "start_time": "2019-09-10T12:00:54.516642Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(train_df[['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
    "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "       'Horizontal_Distance_To_Fire_Points']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.584445Z",
     "start_time": "2019-09-10T12:00:54.546854Z"
    }
   },
   "outputs": [],
   "source": [
    "def categorical_features(df):\n",
    "    size = len(df)\n",
    "    columns_to_keep = []\n",
    "    for column in df.columns:\n",
    "        if 'Soil' in column or 'Wilderness' in column:\n",
    "            frequency = df[column].sum() / size\n",
    "            if frequency >= 0.04:\n",
    "                columns_to_keep.append(column)\n",
    "    print('Columns keeped %s' % columns_to_keep)\n",
    "    return np.array(df[columns_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.635532Z",
     "start_time": "2019-09-10T12:00:54.585955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns keeped ['Wilderness_Area1', 'Wilderness_Area3', 'Wilderness_Area4', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type6', 'Soil_Type10', 'Soil_Type17', 'Soil_Type23', 'Soil_Type29', 'Soil_Type30', 'Soil_Type32', 'Soil_Type33', 'Soil_Type38', 'Soil_Type39']\n"
     ]
    }
   ],
   "source": [
    "categorical = categorical_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.662210Z",
     "start_time": "2019-09-10T12:00:54.637076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:54.686189Z",
     "start_time": "2019-09-10T12:00:54.667801Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.hstack((X, categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:58.307790Z",
     "start_time": "2019-09-10T12:00:58.302956Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "binarizer = LabelBinarizer()\n",
    "y = binarizer.fit_transform(train_df['Cover_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:00:59.893136Z",
     "start_time": "2019-09-10T12:00:59.885170Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:11:17.157443Z",
     "start_time": "2019-09-10T12:11:17.152162Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:01:00.645305Z",
     "start_time": "2019-09-10T12:01:00.640650Z"
    }
   },
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:01:01.088374Z",
     "start_time": "2019-09-10T12:01:01.078270Z"
    }
   },
   "outputs": [],
   "source": [
    "def model2():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:01:01.475986Z",
     "start_time": "2019-09-10T12:01:01.467427Z"
    }
   },
   "outputs": [],
   "source": [
    "def model3():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:01:02.061713Z",
     "start_time": "2019-09-10T12:01:02.049366Z"
    }
   },
   "outputs": [],
   "source": [
    "def model4():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(40, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(40, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:01:06.009991Z",
     "start_time": "2019-09-10T12:01:06.006896Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_and_train(model, epochs=20):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    print(model.metrics_names)\n",
    "    print(model.evaluate(X_train, y_train))\n",
    "    print(model.evaluate(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:02:33.175289Z",
     "start_time": "2019-09-10T12:01:08.512441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ivan/pybr/kaggle-forest-types/venv/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "['loss', 'acc']\n",
      "13608/13608 [==============================] - 0s 26us/sample - loss: 0.5653 - acc: 0.7675\n",
      "[0.5652701917604304, 0.76748973]\n",
      "1512/1512 [==============================] - 0s 27us/sample - loss: 0.6191 - acc: 0.7242\n",
      "[0.6191048879156668, 0.7242063]\n",
      "['loss', 'acc']\n",
      "13608/13608 [==============================] - 0s 26us/sample - loss: 0.5956 - acc: 0.7507\n",
      "[0.5956167677512665, 0.75073487]\n",
      "1512/1512 [==============================] - 0s 27us/sample - loss: 0.6425 - acc: 0.7130\n",
      "[0.6424913898346916, 0.712963]\n",
      "['loss', 'acc']\n",
      "13608/13608 [==============================] - 0s 30us/sample - loss: 0.7150 - acc: 0.7097\n",
      "[0.7149608557817166, 0.70965606]\n",
      "1512/1512 [==============================] - 0s 29us/sample - loss: 0.7490 - acc: 0.6693\n",
      "[0.7489979560413058, 0.6693122]\n",
      "['loss', 'acc']\n",
      "13608/13608 [==============================] - 0s 28us/sample - loss: 0.6514 - acc: 0.7283\n",
      "[0.6513574599939399, 0.72832155]\n",
      "1512/1512 [==============================] - 0s 29us/sample - loss: 0.6826 - acc: 0.6925\n",
      "[0.6825983054423458, 0.6924603]\n"
     ]
    }
   ],
   "source": [
    "for model in [model1(), model2(), model3(), model4()]:\n",
    "    compile_and_train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:03:43.455110Z",
     "start_time": "2019-09-10T12:02:44.733297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "13608/13608 [==============================] - 0s 29us/sample - loss: 0.5127 - acc: 0.7842\n",
      "[0.5126627201125735, 0.7841711]\n",
      "1512/1512 [==============================] - 0s 31us/sample - loss: 0.5793 - acc: 0.7401\n",
      "[0.579335238094683, 0.74007934]\n"
     ]
    }
   ],
   "source": [
    "model = model2()\n",
    "compile_and_train(model, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:04:56.855364Z",
     "start_time": "2019-09-10T12:03:43.456712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "13608/13608 [==============================] - 0s 32us/sample - loss: 0.4586 - acc: 0.8180\n",
      "[0.45864952025800365, 0.8180482]\n",
      "1512/1512 [==============================] - 0s 34us/sample - loss: 0.5328 - acc: 0.7718\n",
      "[0.5328434024538312, 0.7718254]\n"
     ]
    }
   ],
   "source": [
    "model = model1()\n",
    "compile_and_train(model, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:06:17.079461Z",
     "start_time": "2019-09-10T12:04:56.856823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "13608/13608 [==============================] - 1s 41us/sample - loss: 0.5920 - acc: 0.7470\n",
      "[0.5919530842319648, 0.74698704]\n",
      "1512/1512 [==============================] - 0s 36us/sample - loss: 0.6463 - acc: 0.7037\n",
      "[0.6463253315163668, 0.7037037]\n"
     ]
    }
   ],
   "source": [
    "model = model4()\n",
    "compile_and_train(model, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:26:56.525554Z",
     "start_time": "2019-09-10T12:26:56.520983Z"
    }
   },
   "outputs": [],
   "source": [
    "tensorboard_logs = TensorBoard(log_dir='./logs', histogram_freq=1,\n",
    "                               write_graph=True, write_images=True,\n",
    "                               update_freq='epoch')\n",
    "mcp_save = ModelCheckpoint(os.path.join('./keras_models', \n",
    "                                        'modelweights.{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                           save_best_only=True, monitor='val_acc', mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=40, verbose=0, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10,\n",
    "                              verbose=1, min_delta=1e-2, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:23:43.943761Z",
     "start_time": "2019-09-10T12:23:43.926265Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_final():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.0002)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.0002)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:26:45.144567Z",
     "start_time": "2019-09-10T12:26:45.140185Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_final():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-10T12:28:51.550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13608 samples, validate on 1512 samples\n",
      "Epoch 1/500\n",
      "13608/13608 [==============================] - 2s 150us/sample - loss: 1.5217 - acc: 0.3595 - val_loss: 0.9959 - val_acc: 0.5939\n",
      "Epoch 2/500\n",
      "13608/13608 [==============================] - 1s 93us/sample - loss: 1.0899 - acc: 0.5363 - val_loss: 0.8459 - val_acc: 0.6396\n",
      "Epoch 3/500\n",
      "13608/13608 [==============================] - 1s 94us/sample - loss: 0.9804 - acc: 0.5913 - val_loss: 0.7890 - val_acc: 0.6620\n",
      "Epoch 4/500\n",
      "13608/13608 [==============================] - 1s 91us/sample - loss: 0.9086 - acc: 0.6222 - val_loss: 0.7599 - val_acc: 0.6693\n",
      "Epoch 5/500\n",
      "13608/13608 [==============================] - 1s 92us/sample - loss: 0.8870 - acc: 0.6373 - val_loss: 0.7463 - val_acc: 0.6772\n",
      "Epoch 6/500\n",
      "13608/13608 [==============================] - 1s 91us/sample - loss: 0.8597 - acc: 0.6523 - val_loss: 0.7239 - val_acc: 0.6779\n",
      "Epoch 7/500\n",
      "13608/13608 [==============================] - 1s 91us/sample - loss: 0.8329 - acc: 0.6587 - val_loss: 0.7139 - val_acc: 0.6885\n",
      "Epoch 8/500\n",
      "13608/13608 [==============================] - 1s 89us/sample - loss: 0.8228 - acc: 0.6662 - val_loss: 0.6977 - val_acc: 0.6925\n",
      "Epoch 9/500\n",
      "13608/13608 [==============================] - 1s 90us/sample - loss: 0.8144 - acc: 0.6692 - val_loss: 0.7015 - val_acc: 0.6958\n",
      "Epoch 10/500\n",
      "13608/13608 [==============================] - 1s 90us/sample - loss: 0.8054 - acc: 0.6750 - val_loss: 0.6950 - val_acc: 0.6964\n",
      "Epoch 11/500\n",
      "13608/13608 [==============================] - 1s 90us/sample - loss: 0.7981 - acc: 0.6823 - val_loss: 0.6825 - val_acc: 0.6925\n",
      "Epoch 12/500\n",
      "13608/13608 [==============================] - 1s 90us/sample - loss: 0.7886 - acc: 0.6865 - val_loss: 0.6811 - val_acc: 0.7070\n",
      "Epoch 13/500\n",
      "13608/13608 [==============================] - 1s 91us/sample - loss: 0.7938 - acc: 0.6857 - val_loss: 0.6734 - val_acc: 0.7110\n",
      "Epoch 14/500\n",
      "13608/13608 [==============================] - 1s 96us/sample - loss: 0.7843 - acc: 0.6902 - val_loss: 0.6749 - val_acc: 0.7063\n",
      "Epoch 15/500\n",
      "13608/13608 [==============================] - 1s 93us/sample - loss: 0.7898 - acc: 0.6941 - val_loss: 0.6684 - val_acc: 0.7169\n",
      "Epoch 16/500\n",
      "13608/13608 [==============================] - 1s 92us/sample - loss: 0.7830 - acc: 0.6959 - val_loss: 0.6615 - val_acc: 0.7123\n",
      "Epoch 17/500\n",
      "13608/13608 [==============================] - 1s 94us/sample - loss: 0.7743 - acc: 0.6905 - val_loss: 0.6645 - val_acc: 0.7123\n",
      "Epoch 18/500\n",
      "13608/13608 [==============================] - 1s 94us/sample - loss: 0.7693 - acc: 0.6977 - val_loss: 0.6746 - val_acc: 0.7156\n",
      "Epoch 19/500\n",
      "13608/13608 [==============================] - 1s 93us/sample - loss: 0.7766 - acc: 0.7025 - val_loss: 0.6720 - val_acc: 0.6944\n",
      "Epoch 20/500\n",
      "13608/13608 [==============================] - 1s 94us/sample - loss: 0.7714 - acc: 0.7041 - val_loss: 0.6656 - val_acc: 0.7103\n",
      "Epoch 21/500\n",
      "13608/13608 [==============================] - 1s 94us/sample - loss: 0.7758 - acc: 0.7005 - val_loss: 0.6615 - val_acc: 0.7143\n",
      "Epoch 22/500\n",
      "13608/13608 [==============================] - 1s 92us/sample - loss: 0.7749 - acc: 0.7013 - val_loss: 0.6651 - val_acc: 0.7143\n",
      "Epoch 23/500\n",
      "13608/13608 [==============================] - 1s 91us/sample - loss: 0.7790 - acc: 0.7050 - val_loss: 0.6627 - val_acc: 0.7222\n",
      "Epoch 24/500\n",
      " 7936/13608 [================>.............] - ETA: 0s - loss: 0.7587 - acc: 0.7127"
     ]
    }
   ],
   "source": [
    "model = model_final()\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=500,\n",
    "          callbacks=[early_stop, reduce_lr, mcp_save, tensorboard_logs],\n",
    "          validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T11:40:41.495775Z",
     "start_time": "2019-09-10T11:40:41.492011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T02:11:28.245131Z",
     "start_time": "2019-09-10T02:11:28.163916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8373015873015873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.75      0.74       220\n",
      "           2       0.77      0.70      0.73       227\n",
      "           3       0.80      0.83      0.81       211\n",
      "           4       0.93      0.94      0.93       216\n",
      "           5       0.91      0.90      0.90       211\n",
      "           6       0.80      0.78      0.79       206\n",
      "           7       0.92      0.96      0.94       221\n",
      "\n",
      "    accuracy                           0.84      1512\n",
      "   macro avg       0.84      0.84      0.84      1512\n",
      "weighted avg       0.84      0.84      0.84      1512\n",
      "\n",
      "[[166  31   2   0   1   1  19]\n",
      " [ 52 159   1   0  10   5   0]\n",
      " [  0   1 176  11   3  20   0]\n",
      " [  0   0   8 203   0   5   0]\n",
      " [  0  11   2   0 189   9   0]\n",
      " [  0   3  32   5   5 161   0]\n",
      " [  8   1   0   0   0   0 212]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "report(binarizer.inverse_transform(y_val), binarizer.inverse_transform(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:01:48.531689Z",
     "start_time": "2019-09-09T01:59:18.040213Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:02:17.581875Z",
     "start_time": "2019-09-09T02:02:15.266764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'ID': test_ids,\n",
    "                       'Cover_Type': test_pred})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forestypes-venv",
   "language": "python",
   "name": "forestypes-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
